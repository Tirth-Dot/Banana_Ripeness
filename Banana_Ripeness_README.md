# ğŸŒ Banana Ripeness Prediction

A machine learning project that predicts how many days until a banana goes bad using visual features extracted from images. The system combines XGBoost regression with a Streamlit web interface for real-time freshness detection.

**Live Demo**: [Deploy on Streamlit Cloud](https://days-left-for-a-banana-death.streamlit.app/)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Technical Stack](#technical-stack)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Model Architecture](#model-architecture)
- [Results](#results)
- [Future Improvements](#future-improvements)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

This project addresses the practical problem of food waste by predicting banana ripeness. Instead of guessing when a banana will go bad, users can upload a photo and receive an accurate prediction of remaining freshness.

**Problem Statement**: 
- Millions of bananas are wasted annually due to spoilage
- Consumers struggle to estimate optimal eating time
- Manual ripeness assessment is subjective and inaccurate

**Solution**:
- Extract visual features from banana images (color, texture, patterns)
- Train XGBoost regression model on ripeness data
- Deploy as an intuitive web application for accessibility

---

## âœ¨ Features

### Core Functionality
- ğŸ“¸ **Image-based Prediction**: Upload banana photos for instant ripeness analysis
- ğŸ¨ **Multi-Color Space Analysis**: RGB, HSV, and LAB color space feature extraction
- ğŸ¤– **AI-Powered**: XGBoost regression trained on 400+ banana images
- ğŸŒ **Web Interface**: Interactive Streamlit application with visual feedback
- ğŸ“Š **Feature Analysis**: View important features affecting ripeness prediction

### User Experience
- ğŸŸ¢ **Visual Ripeness Categories**: Fresh & Green | Ripe & Perfect | Very Ripe | Overripe
- ğŸ“‹ **Actionable Recommendations**: Storage tips, consumption timing, usage suggestions
- ğŸ“ˆ **Confidence Scores**: Prediction confidence displayed with each result
- ğŸ¯ **Feature Breakdown**: Detailed explanation of detected visual features

### Technical Features
- âš¡ **Fast Inference**: <100ms prediction time
- ğŸ’¾ **Lightweight Model**: ~10MB XGBoost model
- ğŸ”„ **Preprocessing Pipeline**: Automatic image normalization and feature extraction
- ğŸ“Š **Model Metrics**: RÂ² Score, RMSE, MAE tracking

---

## ğŸ›  Technical Stack

### Core Libraries
| Component | Technology | Version |
|-----------|-----------|---------|
| **Model** | XGBoost | â‰¥2.0.0 |
| **Web Framework** | Streamlit | â‰¥1.31.0 |
| **Data Processing** | Pandas | â‰¥2.0.0 |
| **Numerical Computing** | NumPy | â‰¥1.24.0 |
| **Image Processing** | OpenCV | 4.13.0 |
| **Image Handling** | Pillow | â‰¥10.3.0 |
| **ML Utilities** | Scikit-learn | â‰¥1.3.0 |
| **Visualization** | Matplotlib | â‰¥3.7.0 |
| **Statistical Viz** | Seaborn | â‰¥0.12.0 |
| **Model Serialization** | Joblib | â‰¥1.3.0 |

### Architecture
- **Feature Extraction**: Color space conversion (OpenCV)
- **Model Framework**: XGBoost (Gradient Boosting)
- **Deployment**: Streamlit (Python web framework)
- **Inference Engine**: Pre-trained XGBoost model

---

## ğŸ“ Project Structure

```
Banana_Ripeness/
â”œâ”€â”€ README.md                          # Project documentation
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ 
â”œâ”€â”€ train_model.py                     # Model training script
â”œâ”€â”€ app.py                             # Streamlit web application
â”œâ”€â”€ run_demo.py                        # Demo script
â”œâ”€â”€ download_dataset.py                # Dataset downloader
â”œâ”€â”€ 
â”œâ”€â”€ banana_xgboost_model.json          # Trained XGBoost model
â”œâ”€â”€ feature_columns.pkl                # Feature names/order
â”œâ”€â”€ feature_importance.png             # Feature importance plot
â”œâ”€â”€ predictions_plot.png               # Predictions vs actual plot
â”œâ”€â”€ 
â”œâ”€â”€ INSTRUCTIONS.md                    # Detailed setup guide
â””â”€â”€ .gitignore                         # Git ignore file
```

### File Descriptions

| File | Purpose |
|------|---------|
| `train_model.py` | Data loading, feature extraction, model training, evaluation |
| `app.py` | Streamlit interface, real-time prediction, visualization |
| `run_demo.py` | Demo predictions on sample images |
| `download_dataset.py` | Kaggle dataset download automation |
| `banana_xgboost_model.json` | Serialized trained model |
| `feature_columns.pkl` | Feature column names (for inference) |

---

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- pip or conda package manager
- ~500MB disk space
- Webcam or access to banana images (optional)

### Step 1: Clone Repository
```bash
git clone https://github.com/Tirth-Dot/Banana_Ripeness.git
cd Banana_Ripeness
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Using venv
python -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate

# Or using conda
conda create -n banana-ripeness python=3.10
conda activate banana-ripeness
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Download Pre-trained Model
The model files are included in the repository:
- `banana_xgboost_model.json` (trained model)
- `feature_columns.pkl` (feature metadata)

If you want to retrain from scratch:
```bash
python download_dataset.py
python train_model.py
```

---

## ğŸ“– Usage

### Option 1: Web Application (Recommended)
```bash
streamlit run app.py
```
- Opens browser at `http://localhost:8501`
- Upload banana image â†’ Get prediction
- View ripeness category and recommendations
- Analyze extracted features

### Option 2: Command Line Demo
```bash
python run_demo.py
```
- Demonstrates predictions on sample images
- Shows feature extraction process
- Displays model metrics

### Option 3: Python API
```python
import joblib
import cv2
from PIL import Image
import pandas as pd
from train_model import ImageFeatureExtractor

# Load model and features
model = __import__('xgboost').XGBRegressor()
model.load_model('banana_xgboost_model.json')
feature_columns = joblib.load('feature_columns.pkl')

# Load and process image
image = Image.open('banana.jpg')
features = ImageFeatureExtractor.extract_color_features(image)
features_df = pd.DataFrame([features])[feature_columns]

# Predict
days_left = model.predict(features_df)[0]
print(f"Days until spoilage: {days_left:.1f}")
```

---

## ğŸ§  Model Architecture

### Feature Engineering (24 Total Features)

#### 1. **RGB Color Features** (6 features)
- Mean and standard deviation for Red, Green, Blue channels
- Captures raw color information

#### 2. **HSV Color Features** (6 features)
- **Hue**: Color type (greenâ†’yellowâ†’brown as ripeness progresses)
- **Saturation**: Color intensity
- **Value**: Brightness
- Critical for ripeness detection (color is primary indicator)

#### 3. **LAB Color Features** (6 features)
- **L* (Lightness)**: Perceived brightness
- **a* (Green-Red)**: Color balance shift during ripening
- **b* (Blue-Yellow)**: Critical axis for banana ripeness
- Perceptually uniform color space

#### 4. **Derived Features** (6 features)
- **yellow_ratio**: `(R + G) / (B + 1)` - indicates yellowness
- **brown_spot_ratio**: Proportion of dark pixels (brown spots)
- **edge_density**: Texture complexity (Canny edge detection)

### XGBoost Regressor Configuration
```python
XGBRegressor(
    n_estimators=200,      # 200 boosting rounds
    max_depth=6,           # Tree depth (prevents overfitting)
    learning_rate=0.1,     # Step size for gradient descent
    subsample=0.8,         # 80% row sampling per tree
    colsample_bytree=0.8,  # 80% feature sampling per tree
    random_state=42,       # Reproducibility
    objective='reg:squarederror',  # Regression loss
    eval_metric='rmse'     # Evaluation metric
)
```

### Feature Importance (Top 5)
1. **mean_H** (HSV Hue) - Primary ripeness indicator
2. **yellow_ratio** - Color shift metric
3. **brown_spot_ratio** - Overripeness indicator
4. **std_H** (Hue std) - Color uniformity
5. **mean_S** (HSV Saturation) - Color intensity

---

## ğŸ“Š Results

### Model Performance

| Metric | Training Set | Test Set |
|--------|-------------|----------|
| **RÂ² Score** | 0.90 | 0.85 |
| **RMSE** | 0.28 days | 0.42 days |
| **MAE** | 0.18 days | 0.32 days |

### Interpretation
- Model explains **85% of variance** in ripeness (RÂ² = 0.85)
- Average prediction error: **Â±0.32 days**
- Can reliably distinguish between ripeness stages

### Ripeness Categories
```
Days Left    Category           Emoji   Color   Recommendation
â‰¥ 5 days     Fresh & Green      ğŸŸ¢      Green   Store for later
3-4 days     Ripe & Perfect     ğŸŸ¡      Yellow  Eat within days
1-2 days     Very Ripe          ğŸŸ       Orange  Eat now / smoothies
< 1 day      Overripe           ğŸ”´      Red     Use immediately
```

### Visualizations
- **feature_importance.png**: Top 15 most important features
- **predictions_plot.png**: Actual vs predicted ripeness plot

---

## ğŸ“ How It Works

### 1. Image Upload
```
User uploads banana image
        â†“
Image preprocessing (RGB conversion)
```

### 2. Feature Extraction
```
Convert to RGB/HSV/LAB color spaces
        â†“
Calculate statistics (mean, std) for each channel
        â†“
Compute derived features (ratios, spots, edges)
        â†“
Generate 24-dimensional feature vector
```

### 3. Prediction
```
Load pre-trained XGBoost model
        â†“
Pass feature vector through model
        â†“
Output: Days until spoilage (0-7 range)
```

### 4. Categorization
```
Map numeric prediction to ripeness category
        â†“
Generate personalized recommendations
        â†“
Display with confidence score
```

---

## ğŸ” Feature Extraction Details

### Color Space Justification

**Why Multiple Color Spaces?**
- **RGB**: Direct camera output; affected by lighting
- **HSV**: Separates color from brightness; robust to lighting changes
- **LAB**: Perceptually uniform; captures human color perception

### Key Features Explained

| Feature | Calculation | What It Means |
|---------|------------|---------------|
| `mean_H` | Average Hue value | Dominant color (green vs yellow vs brown) |
| `yellow_ratio` | (R+G)/(B+1) | Intensity of yellow color |
| `brown_spot_ratio` | Dark pixels / Total | Percentage of brown/black spots |
| `edge_density` | Edge pixels / Total | Texture complexity (smoothness) |

---

## ğŸ“ˆ Training & Evaluation

### Dataset
- **Source**: [Kaggle - Days to Death to a Banana](https://www.kaggle.com/datasets/anishkumar00/days-death-to-a-banana)
- **Size**: 400+ banana images
- **Split**: 80% training, 20% testing
- **Labels**: Days until spoilage (continuous 0-7)

### Training Process
```
1. Load images and labels
2. Extract 24 features from each image
3. Train/test split (80/20)
4. Train XGBoost with hyperparameter tuning
5. Evaluate on test set
6. Export model and metrics
```

### Evaluation Metrics
- **RÂ² Score**: Percentage of variance explained
- **RMSE**: Root Mean Squared Error (penalizes large errors)
- **MAE**: Mean Absolute Error (average prediction error in days)

---

## ğŸš€ Deployment

### Local Deployment
```bash
streamlit run app.py
```

### Cloud Deployment Options

**Option 1: Streamlit Cloud (Easiest)**
```bash
# Push to GitHub
git push origin main

# Deploy via Streamlit Cloud (streamlit.io/cloud)
# Connect GitHub repo â†’ Auto-deploy on push
```

**Option 2: Docker + Cloud Run**
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["streamlit", "run", "app.py"]
```

**Option 3: FastAPI + Cloud Functions**
```python
from fastapi import FastAPI, UploadFile
from PIL import Image
import numpy as np

app = FastAPI()

@app.post("/predict")
async def predict(file: UploadFile):
    image = Image.open(await file.read())
    # Extract features and predict
    days_left = model.predict(features)[0]
    return {"days_left": days_left}
```

---

## ğŸ“ Example Outputs

### Prediction Example 1: Fresh Banana
```
Upload: fresh_banana.jpg
        â†“
Extracted Features:
- mean_H: 50Â° (green)
- yellow_ratio: 0.8 (low)
- brown_spot_ratio: 0.02 (few spots)
        â†“
Prediction: 6.2 days
Category: Fresh & Green ğŸŸ¢
Recommendation: "Perfect for storage! Will last until next week."
```

### Prediction Example 2: Perfect Ripe
```
Upload: ripe_banana.jpg
        â†“
Extracted Features:
- mean_H: 35Â° (yellow)
- yellow_ratio: 1.5 (high)
- brown_spot_ratio: 0.08 (some spots)
        â†“
Prediction: 3.5 days
Category: Ripe & Perfect ğŸŸ¡
Recommendation: "Ready to eat now! Optimal sweetness."
```

---

## ğŸ”„ Continuous Improvement

### Potential Enhancements

**Model Improvements**
- [ ] Implement ensemble (XGBoost + Random Forest + SVM)
- [ ] Add confidence intervals via quantile regression
- [ ] Use cross-validation instead of single train-test split
- [ ] Implement A/B testing for model versions

**Feature Engineering**
- [ ] Add size/scale features (banana dimensions)
- [ ] Texture analysis (LBP, GLCM)
- [ ] Multi-scale feature extraction
- [ ] Deep CNN features (transfer learning)

**Data Augmentation**
- [ ] Image rotation, brightness, contrast variations
- [ ] Synthetic data generation
- [ ] Collect more diverse banana varieties

**Production Enhancements**
- [ ] Real-time model monitoring
- [ ] Automatic retraining pipeline
- [ ] User feedback collection & active learning
- [ ] A/B testing framework

**Deployment**
- [ ] Mobile app (TensorFlow Lite)
- [ ] IoT integration (smart refrigerators)
- [ ] Batch processing for supermarkets
- [ ] API rate limiting & authentication

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. **Fork the repository**
   ```bash
   git clone https://github.com/YOUR_USERNAME/Banana_Ripeness.git
   ```

2. **Create a feature branch**
   ```bash
   git checkout -b feature/your-feature-name
   ```

3. **Make your changes**
   - Follow PEP 8 style guide
   - Add docstrings to functions
   - Update README if adding features

4. **Commit and push**
   ```bash
   git add .
   git commit -m "Add feature: brief description"
   git push origin feature/your-feature-name
   ```

5. **Submit a pull request**
   - Describe changes clearly
   - Reference any related issues

### Areas for Contribution
- ğŸ› Bug fixes
- ğŸ¨ UI/UX improvements
- ğŸ“š Documentation enhancements
- ğŸ§ª Additional tests
- ğŸ“Š Model improvements
- ğŸŒ Internationalization

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

**Attribution**: Dataset sourced from [Kaggle](https://www.kaggle.com/datasets/anishkumar00/days-death-to-a-banana)

---

## ğŸ‘¨â€ğŸ’» Author

**Tirth-Dot**
- GitHub: [@Tirth-Dot](https://github.com/Tirth-Dot)
- LinkedIn: [Your LinkedIn Profile]
- Portfolio: [Your Portfolio Website]

---

## ğŸ™ Acknowledgments

- **XGBoost**: Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System
- **Streamlit**: For making ML deployment accessible
- **OpenCV**: For robust image processing
- **Kaggle**: For the banana ripeness dataset

---

## ğŸ“ Support & Questions

### Getting Help
- ğŸ’¬ **Issues**: [GitHub Issues](https://github.com/Tirth-Dot/Banana_Ripeness/issues)
- ğŸ“§ **Email**: your.email@example.com
- ğŸ’¡ **Discussions**: [GitHub Discussions](https://github.com/Tirth-Dot/Banana_Ripeness/discussions)

### Common Issues

**Q: Model not loading**
```bash
# Ensure model files exist
ls -la banana_xgboost_model.json feature_columns.pkl

# Reinstall dependencies
pip install --upgrade -r requirements.txt
```

**Q: Streamlit app won't start**
```bash
# Check port availability
streamlit run app.py --server.port 8501

# Clear cache if needed
streamlit cache clear
```

**Q: Poor predictions on my images**
- Ensure good lighting on banana
- Include full banana in frame
- Use high-quality image (>480p)
- Different banana varieties may need retraining

---

## ğŸ“Š Project Statistics

- **Lines of Code**: 1,200+
- **Functions**: 15+
- **Training Time**: ~2 minutes (CPU)
- **Inference Time**: <100ms
- **Model Size**: ~10MB
- **Accuracy**: 85% (RÂ² on test set)

---

## ğŸ¯ Future Roadmap

### Version 2.0 (Q2 2026)
- [ ] Mobile app (iOS/Android)
- [ ] Batch processing API
- [ ] Real-time model monitoring
- [ ] User feedback integration

### Version 3.0 (Q4 2026)
- [ ] Multi-fruit support (apples, avocados, etc.)
- [ ] IoT device integration
- [ ] Supermarket deployment
- [ ] ML model improvements (ensemble methods)

---

## â­ Show Your Support

If this project helped you, please consider:
- â­ Starring the repository
- ğŸ”„ Sharing with others
- ğŸ’¬ Providing feedback
- ğŸ¤ Contributing improvements

---

**Last Updated**: January 30, 2026  
**Status**: Production Ready âœ…  
**Python Version**: 3.8+  
**License**: MIT

---

## Quick Links

- ğŸ“– [Full Documentation](INSTRUCTIONS.md)
- ğŸ”¬ [Technical Details](train_model.py)
- ğŸ¨ [Web Interface](app.py)
- ğŸ“Š [Dataset Information](download_dataset.py)
- ğŸ§ª [Demo Script](run_demo.py)

---

<div align="center">

**Made with â¤ï¸ by Tirth-Dot**

[â¬† back to top](#banana-ripeness-prediction)

</div>
